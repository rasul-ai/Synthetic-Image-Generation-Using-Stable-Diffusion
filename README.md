# Synthetic-Image-Generation-Using-Stable-Diffusion
## Overview
I have created this project to focus on generating synthetic images using a text-to-image model based on stable diffusion techniques. The model allows users to input descriptive text and generate corresponding images, simulating real-world scenarios or artistic visuals.
## Directory Structure
The folder structure for the project is as follows:
```
Diffusion/
│
├── dataset/
├── Generated_sample/
├── text_to_image/
    ├── img_captioning.py
    ├── inference.py
    ├── job.sh
    ├── job_5256095.txt
    ├── train_text_to_image.py
```

### 1. `dataset/`
This directory contains three images and a `metadata.jsonl` file. Each image represents a pair of denim jeans laid flat on a white background. The JSONL file contains metadata for each image, including the file name and a detailed description of the image content. These descriptions will be used for training the text-to-image model.

Example entries in `metadata.jsonl`:

```json
{
  "file_name": "11 (3).JPG",
  "text": "A single pair of denim jeans laid flat on a white background, viewed from the back. The jeans have a slightly faded \
appearance with visible back pockets. The legs are spread apart with natural creases, and the back rise area is clearly visible.\
A small black square reference marker is placed near the upper right corner of the image."
}
```

### 2. `Generated_sample/`

This folder stores the synthetic images generated by the trained model. After running the `inference.py` script, this directory will be populated with images based on the text prompts provided.

### 3. `text_to_image/`

This folder contains the primary code for training and inferring the model.

- **img_captioning.py**: This script likely handles the image captioning task, where the model may need to generate captions for a set of images or work as part of the training pipeline to align text with image features.
  
- **inference.py**: This script handles the inference process for generating images from text. It takes in a textual prompt and outputs an image that represents the prompt.

- **job.sh**: This is a shell script that may be used to submit a job to a computing cluster (likely for large-scale training) or automate some steps in the model training/inference process.

- **job_5256095.txt**: This file seems to be a log or output file from a specific job run on the system. It may contain error logs, output results, or training progress.

- **train_text_to_image.py**: This script handles the training of the text-to-image diffusion model. It likely leverages a dataset of text-image pairs to fine-tune a model capable of synthesizing images from new text prompts.

## How to Use

### 1. Training the Model
To train the model using your dataset, use the `train_text_to_image.py` script. Before running it, ensure that your dataset is properly structured and contains appropriate image-caption pairs.

Example command:
```bash
python train_text_to_image.py --dataset dataset_path --epochs 100

